{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep apache-beam==2.10.0 || pip install apache-beam[gcp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep tensorflow==1.12.0 || pip install tensorflow==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'qwiklabs-gcp-3f19cbba7aa3ae63'\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['CLOUDSDK_PYTHON'] = 'python3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'train': \"\"\"\n",
    "    SELECT DISTINCT\n",
    "      bucket_name,\n",
    "      CONCAT(\"gs://project-sample/dataset1/\", CAST(product_id AS STRING), \".jpeg\") as product_id,\n",
    "      REPLACE(product_name, '\\\\n', ' ') AS product_name,\n",
    "      REPLACE(description, '\\\\n', ' ') AS description\n",
    "    FROM `qwiklabs-gcp-3f19cbba7aa3ae63.project.raw`\n",
    "    WHERE\n",
    "      bucket_name is not null\n",
    "      and product_id is not null\n",
    "      and product_name is not null\n",
    "      and description is not null\n",
    "      AND MOD(ABS(FARM_FINGERPRINT(CAST(product_id AS STRING))), 1000) < 700\n",
    "    \"\"\",\n",
    "\n",
    "    'eval': \"\"\"\n",
    "    SELECT DISTINCT\n",
    "      bucket_name,\n",
    "      CONCAT(\"gs://project-sample/dataset1/\", CAST(product_id AS STRING), \".jpeg\") as product_id,\n",
    "      REPLACE(product_name, '\\\\n', ' ') AS product_name,\n",
    "      REPLACE(description, '\\\\n', ' ') AS description\n",
    "    FROM `qwiklabs-gcp-3f19cbba7aa3ae63.project.raw`\n",
    "    WHERE\n",
    "      bucket_name is not null\n",
    "      and product_id is not null\n",
    "      and product_name is not null\n",
    "      and description is not null\n",
    "      AND MOD(ABS(FARM_FINGERPRINT(CAST(product_id AS STRING))), 1000) >= 700 AND MOD(ABS(FARM_FINGERPRINT(CAST(product_id AS STRING))), 1000) < 900\n",
    "    \"\"\",\n",
    "\n",
    "    'test': \"\"\"\n",
    "    SELECT DISTINCT\n",
    "      bucket_name,\n",
    "      CONCAT(\"gs://project-sample/dataset1/\", CAST(product_id AS STRING), \".jpeg\") as product_id,\n",
    "      REPLACE(product_name, '\\\\n', ' ') AS product_name,\n",
    "      REPLACE(description, '\\\\n', ' ') AS description\n",
    "    FROM `qwiklabs-gcp-3f19cbba7aa3ae63.project.raw`\n",
    "    WHERE\n",
    "      bucket_name is not null\n",
    "      and product_id is not null\n",
    "      and product_name is not null\n",
    "      and description is not null\n",
    "      AND MOD(ABS(FARM_FINGERPRINT(CAST(product_id AS STRING))), 1000) >= 900\n",
    "    \"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from apache_beam.io.gcp.bigquery import BigQueryDisposition\n",
    "\n",
    "# This will clean and validate the rows\n",
    "class CleanRow(beam.DoFn):\n",
    "  def process(self, element):\n",
    "    def rm_whitespaces(v):\n",
    "        return v.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    \n",
    "    def img_exists(url):\n",
    "        from apache_beam.io.gcp.gcsio import GcsIO\n",
    "        return GcsIO().exists(path=url)\n",
    "    \n",
    "    # removing special characters from fields\n",
    "    element['description'] = rm_whitespaces(element['description'])\n",
    "    element['product_name'] = rm_whitespaces(element['product_name'])\n",
    "    \n",
    "    # making sure the image exists\n",
    "    if not img_exists(element['product_id']):\n",
    "        return\n",
    "    \n",
    "    yield element\n",
    "\n",
    "\n",
    "def preprocess(runner):\n",
    "  job_name = 'test-dataset-cleaning' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "  print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "\n",
    "  options = {\n",
    "    'staging_location': 'gs://project-sample/out/tmp/staging',\n",
    "    'temp_location': 'gs://project-sample/out/tmp',\n",
    "    'job_name': job_name,\n",
    "    #'requirements_file': 'requirements_cleaning.txt',\n",
    "    'project': PROJECT,\n",
    "    'runner': runner,\n",
    "  }\n",
    "  \n",
    "  #instantiate PipelineOptions object using options dictionary\n",
    "  opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "\n",
    "  #instantantiate Pipeline object using PipelineOptions\n",
    "  with beam.Pipeline(options=opts) as p:\n",
    "    for mode in ['train', 'eval', 'test']:\n",
    "        q = query[mode]\n",
    "        (\n",
    "          p | 'read_{}'.format(mode) >> beam.io.Read(beam.io.BigQuerySource(query=q, use_standard_sql=True))\n",
    "            | 'clean_{}'.format(mode) >> beam.ParDo(CleanRow())\n",
    "            | 'write_{}'.format(mode) >> beam.io.Write(beam.io.BigQuerySink(\n",
    "                write_disposition=BigQueryDisposition.WRITE_TRUNCATE,\n",
    "                project='qwiklabs-gcp-3f19cbba7aa3ae63',\n",
    "                dataset='project',\n",
    "                table='model_dataset1_{}'.format(mode)))\n",
    "        )\n",
    "  print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(\"DirectRunner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(\"DataflowRunner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
